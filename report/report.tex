\documentclass[a4paper]{article}

\usepackage{geometry}
\usepackage[hidelinks]{hyperref}

\usepackage[backend=biber,natbib]{biblatex}
\bibliography{library}

\title{Cross-Platform Communication of Lazy Expression\\\Large{Report for Compiler Construction}}
\author{Camil Staps \and Erin van der Veen}

\newcommand{\abcstar}{\raisebox{1pt}{$\star$}}
\newcommand{\abcs}{ABC\kern .1em\abcstar}

\begin{document}

\maketitle

This is an overview of changes we made to the original framework provided by John.
It is not chronological.
This document is meant to give an overview of the work that has been done, not to describe all the implementation details.

\section*{Ecosystem}
\begin{itemize}
	\item
		We started rewriting the ABC optimiser, bytecode generator and interpreter,
			going through all code at least once to understand the setup.
		This was not strictly necessary except for us to better understand the system.
		The bytecode generator and interpreter share more code now, making modifications easier
			(of course, sharing code was more difficult when the interpreter was still generated).
		The ABC optimiser now uses constructors for almost all ABC instructions, instead of plain strings,
			making the code more readable and extensible.

	\item
		We added test scripts and used GitLab's continuous integration tools to make sure commits do not break stuff.
		All `small examples' except \texttt{copyfile} are included (and working).
		Additionally, we added several small tests with special kinds of data types to test these (and their garbage collection) properly.
		We also added some larger test programs:
			an IKS interpreter which uses polymorphic functions in dynamics;
			a brainfuck interpreter (running a brainfuck interpreter in brainfuck);
			a sudoku solver;
			a test with the generic compression function in \texttt{Data.GenCompress} and special data types.

	\item
		We created a graphical debugger \`a la \texttt{gdb}, with which you can step through ABC(\abcstar) code and see the effect on the stacks and heap%
			\footnote{For a short demo of the debugger, see \url{https://cloo.gl/NTU0}.}.
		Several improvements can be made to this (rewinding, breakpoints) --- it was only a side project.
		The debugger has helped resolve several bugs quickly.

	\item
		All this leads to the following tools:
		\texttt{optimise} to optimise ABC code (ABC $\to$ \abcs);
		\texttt{bytecode} to generate bytecode (ABC/\abcs\ $\to$ obc);
		\texttt{link} to link bytecode (obc $\to$ bc)%
			\footnote{Alternatively, use \texttt{bytecode} on all \abcs\ files required by a module to create a bc file directly.};
		\texttt{interpret} to interpret bytecode (bc);
		\texttt{debug} to debug bytecode (bc).
		We used a bash script to chain these tools together and run tests.

		The tools are documented with a help text (run with \texttt{-h}) and in \texttt{doc/tools.md}.
\end{itemize}

\section*{Bytecode}
\begin{itemize}
	\item
		We created a binary bytecode format.
		In the original setup, a bytecode file was an ASCII file with decimal integers separated by whitespace.
		We now have a binary format.
		The format is optimised for space, such that instructions, literals, stack offsets etc. only take as much bytes as needed.
		(During interpretation, every instruction and argument comprises a full word, so that everything is well-aligned.)

	\item
		A symbol table was added to the bytecode format.
		This is required to resolve descriptors with a Clean host program.

		Along with this, we changed the way relocations are stored.
		Initially, there were four sets of relocations (code-code, code-data, data-code, data-data).
		Now, there are two sets of relocations (code, data), and a relocation contains an index to the code/data segment and an index to the symbol table.

		The symbol table also made a linker possible.
		The linker uses a minimal amount of new code:
			it reuses the parser in the interpreter and the label tree of the code generator.
		Thus, we can now generate bytecode for module one at a time and then link them together.

	\item
		We added record descriptors.
\end{itemize}

\section*{Interpreter}
\begin{itemize}
	\item
		We added many instructions for reals, and many specialized instructions for \texttt{\_system.abc}.
		The interpreter can now use the real StdEnv (the original used a custom, stripped down StdEnv), although not all printing functionality has been implemented yet.

	\item
		We added a copying garbage collector.
		The earlier compacting garbage collector has been removed; we decided it was better to implement something crude but working,
			as an efficient garbage collector is not at the core of the project.
		For this reason, the copying collector can also still be made more efficient.

	\item
		We made it possible to run the interpreter with 64-bit integers and reals.
		This involved changing offsets for curried functions, arrays, and perhaps more.
		In the bytecode, labels, integers and reals take up 64 bits.
		On the 32-bit version, the upper half is discarded.
		(Thus, a real takes up one B-stack element, so we assume the 64-bit version of the compiler.)
\end{itemize}

\section*{Optimisations}
\begin{itemize}
	\item
		The ABC optimiser now removes jumps to labels immediately following the jump.

	\item
		The interpreter can now use computed goto's (`threaded code').
		This gives a speed-up of around 25\% on nfib (for which it has the highest speed-up).
		Because threaded code is impossible to debug, it is also still possible to build an interpreter without.
		This is done using preprocessor directives, so that we need only maintain one code base.
\end{itemize}

\section*{Node copying}
\begin{itemize}
	\item
		We copy HNFs from the interpreter to the host.
		This is currently only possible for descriptors that exist in the host.
		We need to add descriptors that do not exist in the host to the host to fix this.
		Doing this requires some work, but the implementation is straightforward.
		We therefore decided to focus on more interesting aspects.

	\item
		Because we copy lazily, the host may have many references to the interpreter at some moment.
		Consider for instance \texttt{reverse (take 100 (interpret primes))}.
		We interpret a list of primes, take 100 elements and reverse them.
		The actual integers are not copied from the interpreter until they need to be printed.
		This is after reversal of the list, so there are at some point 100 references to the interpreter.

		A reference from the host to the interpreter is a finalizer%
			\footnote{A finalizer contains a (C) function pointer, an integer argument.
				All finalizers on the heap are stored in a linked list.
				When a finalizer is garbage collected, the C function is called with the argument.}.
		The integer is a pointer to the node on the interpreter heap.
		When the interpreter performs garbage collection, it
			(1) marks all relevant\footnotemark\ finalizers so that these nodes are not removed, and
			(2) updates all the references in the finalizers.
		\footnotetext{%
			We only consider finalizers that point to the interpreter heap.
			This is required when other parts of a program use finalizers, or when multiple interpreters run alongside each other.}

		The reference to the interpreter itself (code, data, heap, etc.) is a finalizer as well.
		That way, when the host does not requires the interpreter any more, its memory is freed as well.

	\item
		Applying interpreted functions to native data (e.g. \texttt{(interpret sum) [0..10]}) is possible in some environments.
		For now, the interpreter must have the descriptors of the arguments.
		It is possible to apply functions partially applied in the interpreter (e.g. \texttt{(interpret (map square)) [0..10]}).
		It is not yet possible to apply higher-order functions to host functions (e.g. \texttt{(interpret map) square [0..10]}).

		Also, we still need to ensure that nodes referenced from the interpreter are not garbage collected.
		As discussed, we need to keep an array of references in the host for this.
		In the end we did not have time for this.
\end{itemize}

\section*{Demo projects}
For any meaningful application we need to be able to apply interpreted functions to native data.
Since this is not fully implemented yet, we do not have demo projects using the interpreter from a Clean host program.
However, we have thought about possible applications.

\begin{itemize}
	\item
		A compiler with language extensions.
		Create a compiler which accepts a list of plugins (given from the command line).
		A plugin is a bytecode file containing a collection of functions.
		For instance, it can supply a function with type \texttt{AST -> Either Error AST} to apply a transformation,
			or a function with type \texttt{ABC -> Either Error ABC} to optimise generated code.

	\item
		A bot contest runner.
		Define a game that can be played by bots.
		Create a program that takes a number of bots supplied on the command line.
		A bot is a bytecode file containing a function to perform moves.
		The host program runs a game or competition between these bots.

	\item
		A distributed task scheduler.
		The slaves run the interpreter, the master sends expressions to the slaves to evaluate.
		These expressions can be part of a mining task in blockchain applications or so.
		By interpreting the expression, slaves do not need any knowledge of the task they are performing.
		Such things are also needed in systems like the World Community Grid\footnote{\url{https://www.worldcommunitygrid.org/}},
			which lets any device be part of a large distributed cluster.
		(Of course, for applications like this a JIT compiler would be a must for efficiency reasons.)
\end{itemize}

\section*{Loose ends \& further work}
\begin{itemize}
	\item
		There are some missing cases in the node copying functionality, as mentioned above.
		In particular, it must be made possible to work with descriptors which do not exist in the host/interpreter.
		Also garbage collection for host nodes referenced from the interpreter must be implemented.
	\item
		ABC instructions have been implemented in the bytecode generator and the interpreter as needed, to avoid writing untested code.
		In particular, not all printing functionality from \texttt{\_system.abc} has been implemented.
		The instruction set needs to be expanded.
	\item
		We'd like to adapt \texttt{clm} and/or \texttt{cpm} to be able to generate bytecode files.
		We then also need a way to generate 64-bit ABC on 32-bit machines.
	\item
		The node copying functionality is broken for (records with unboxed) reals, because they are stored differently in the host and the interpreter.
		We need a good way to copy reals properly.
	\item
		When copying reals works, we can look at adding functionality to SoccerFun to share teams with other players using our serialisation/interpretation functions.
	\item
		A JIT compiler would improve performance.
	\item
		Ideally, we extend the Clean runtime system with an exception mechanism to be able to catch errors in the interpreter and not crash the host.
\end{itemize}


\end{document}
